# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# A good robots.txt file is important for SEO.
#
# You can use it to block crawlers from accessing parts of your site that you don't want them to see.
# For example, you can block them from accessing your admin pages or your API endpoints.

User-agent: *
Allow: /

Sitemap: https://pigoat.web.app/sitemap.xml
